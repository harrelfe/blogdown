---
title: Statistically Efficient Ways to Quantify Added Predictive Value of New Measurements
author: "Frank Harrell"
date: '2018-10-17'
categories: []
link-citations: yes
modified: ''
slug: addvalue
summary: Researchers have used contorted, inefficient, and arbitrary analyses to demonstrated
  added value in biomarkers, genes, and new lab measurements.  Traditional statistical
  measures have always been up to the task, and are more powerful and more flexible.  It's
  time to revisit them, and to add a few slight twists to make them more helpful.
tags:
- prediction
- sample-size
- validation
- accuracy-score
- biomarker
- diagnosis
- medicine
- reporting
- 2018
bibliography: harrelfe.bib
---



<style>
p.caption {
  font-size: 0.6em;
}
pre code {
  overflow: auto;
    word-wrap: normal;
    white-space: pre;
    }
</style>
<p class="rquote">
When the outcomme variable Y is continuous, there are only three measures of added value that are commonly used: increase in <span class="math inline">\(R^2\)</span>, decrease in mean squared prediction error, and decrease in mean absolute prediction error. Why have so many measures been invented when Y is binary or censored?
</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>A recurring topic in clinical and translational research is the assessment of new information provided by molecular, physiologic, imaging, and other biomarkers. The notion of added value is in the predictive sense, either when diagnosing a hidden disease, e.g., predicting current status using a binary or ordinal logistic model, or when predicting future events, e.g., using a time-to-event statistical model to predict future disease occurrence, recurrence of disease, or occurrence of a clinical event such as death or stroke.</p>
<p>Before getting into purely analytical issues, note that there are many study design issues. One of the most common mistakes, sometimes intentional, is to fail to collect variables that are available in medical practice to put into the base model. This leads to inadequate adjustment for prior information, setting the bar too low when measuring added value of new information. Other common mistakes are categorizing some of the adjustment variables, resulting in residual confounding and failure to adjust for the real background variables, and categorizing new continuous measurements, resulting in understatement of their added value. Without knowing it, many translational researchers, by dichotomizing new biomarkers, are requiring additional biomarkers to be measured to make up for the lost information in dichotomized markers.</p>
</div>
<div id="how-did-we-get-here" class="section level1">
<h1>How Did We Get Here</h1>
<p>Statisticians have no better sense of history than other scientists. In the quest for publishing new ideas, measures of added value are constantly being invented by statisticians, without asking whether older methods already solve the problem at hand. Some of the examples of measures that are commonly used but are not needed in this setting are the <span class="math inline">\(c\)</span>-index (<span class="citation">Harrell et al. (<a href="#ref-har82">1982</a>)</span>; area under the ROC curve if the outcome is binary), and <a href="https://onlinelibrary.wiley.com/toc/10970258/27/2">IDI and NRI</a>. They are not needed because measures based on standard regression methods are not only adequate to the task, but are more powerful and <strong>more flexible and insightful</strong>, especially when interactions are involved. Especially problematic are measures such as the categorical version of NRI (net reclassification improvement) which not only requires arbitrary categorization of risk estimates but then goes on to use inefficient binary summaries from them. Pencina (personal communication) has regretted including statistical tests for these measures in his highly-cited paper, as these tests have nowhere near the power of the gold-standard likelihood ratio test.</p>
<p>Comparing two c-indexes (one from the base model and one from the larger model containing the new biomarkers) is a low-power procedure. This is because the c-index is a rank measure (the concordance probability from the Wilcoxon test or Somers’ <span class="math inline">\(D_{xy}\)</span> rank correlation) that does not sufficiently reward extreme predictions that are correct<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. And taking the difference between two c-indexes corresponds to taking the difference in two Wilcoxon statistics, which is never done. Instead, a head-to-head comparison is demanded. This can be done by using a different U-statistic based on all possible pairs of observations and counting the fraction of pairs for which one model is “more concordant” with the outcome than the other model. This respects pairings of pairings, and is implemented in the R <code>Hmisc</code> package <code>rcorrp.cens</code> function. Still, this is not as powerful as the likelihood ratio <span class="math inline">\(\chi^2\)</span> test.</p>
<p>Worse than any of these problems is the continued use of <a href="/post/class-damage">discontinuous improper accuracy scoring rules</a> such as sensitivity, specificity, precision, and recall.</p>
</div>
<div id="key-measures" class="section level1">
<h1>Key Measures</h1>
<p>There are three gold standards, and statisticians have too often tried to forget them in the search for novelty:</p>
<ul>
<li>frequentist: log-likelihood, including the likelihood ratio <span class="math inline">\(\chi^2\)</span> test (LR) and AIC</li>
<li>Bayesian: log-likelihood + log prior, including various Bayesian information criteria</li>
<li>explained variation in Y</li>
</ul>
<p>Methods based on one of these gold standards are simpler, more powerful, and allow for greater complexity. The best example of handling complexity will be demonstrated in the case study below, in which the new marker interacts with a standard variable (there, age) when predicting disease probability.</p>
<p>In the binary outcome (Y) case, there are two commonly used proper accuracy scores: the logarithmic accuracy score (a per-observation log-likelihood), and the quadratic accracy score (Brier score; mean squared error). The log-likelihood can be turned into a 0-1 pseudo <span class="math inline">\(R^2\)</span> measure: <span class="math inline">\(1 - \exp(-\text{LR} / n)\)</span>. The only thing going against pseudo <span class="math inline">\(R^2\)</span> is the difficulty in interpreting its absolute value. But it is excellent for comparing two or more models, even though examining increases in LR is better.</p>
<p>Explained outcome variation is another key type of measure. In the linear model, the traditional <span class="math inline">\(R^2\)</span> is often used. This is SSR / SST where SSR is the sum of squares due to regression (the sum of squares of differences between predicted values and the mean predicted value), and SST is the sum of squares total, which is n-1 times the variance of Y. <span class="math inline">\(R^2\)</span> may also be written as SSR / (SSR + SSE) where SSE is the sum of squared residuals. In the linear model, <span class="math inline">\(R^2\)</span> and the log-likelihood are measuring the same thing since LR = <span class="math inline">\(-n \log(1 - R^{2})\)</span>.</p>
<p>We can re-express <span class="math inline">\(R^2\)</span> as <span class="math inline">\(\frac{\text{var}(\hat{Y})}{\text{var}(Y)}\)</span> where <span class="math inline">\(\hat{Y} = X \hat{\beta}\)</span> is the linear predictor (predicted mean, for the linear model).</p>
<p><span class="math inline">\(R^2\)</span> can equivalently be written as the ratio of the explained variance to the sum of explained and unexplained variance. The unexplained variance is the variance of the residuals in the linear model. For a probability model, the natural way to express the proportion of explained variance is through the predicted probabilities that Y=1, denoted by <span class="math inline">\(\hat{P}\)</span>. The <span class="math inline">\(R^2\)</span> measure for a binary Y model is then <span class="math display">\[\frac{\text{var}(\hat{P})}{\text{var}(\hat{P}) + \sum_{i}^{n} \hat{P}_{i} (1 - \hat{P}_{i}) / n}\]</span>
where <span class="math inline">\(\text{var}(\hat{P})\)</span> is the sample variance of the <span class="math inline">\(n\)</span> <span class="math inline">\(\hat{P}_{i}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p><span class="citation">Kent and O’Quigley (<a href="#ref-ken88mea">1988</a>)</span> have extended the idea of the fraction of explained variation in the outcome to various nonlinear models including those used in survival analysis. The SST or var(Y) is distribution-specific. The beauty of this approach is its focus on the variance of <span class="math inline">\(\hat{Y}\)</span>, which is independent of the prevalence of Y=1 in the binary case and of the amount of censoring in time-to-event analysis. See also <span class="citation">B. Choodari-Oskooei, Royston, and Parmar (<a href="#ref-cho12simII">2012</a>)</span> and <span class="citation">Babak Choodari-Oskooei, Royston, and Parmar (<a href="#ref-cho12simI">2012</a>)</span>.</p>
<p>A different type of key measure will also be exemplified in the case study: differences in predicted values between the base model and the expanded model.</p>
<div id="relative-explained-variation" class="section level2">
<h2>Relative Explained Variation</h2>
<p>Relative explained variation is a simple concept that has the extra advantage of being completely free of the distribution of Y and the customized error variance or SST necessary for computing the proportion of explained variance for distributions other than the normal. For a linear model relative explained variation is the ratio of the <span class="math inline">\(R^2\)</span> for the base model to the larger <span class="math inline">\(R^2\)</span> for the combined model that contains also the new markers being tested. And since for <span class="math inline">\(R^{2} \leq 0.25\)</span>, <span class="math inline">\(-n \log(1 - R^{2})\)</span> is approximately <span class="math inline">\(n R^{2}\)</span>, the relative variation explained by the base variables is approximately equal to the <em>adequacy index</em> discussed in the maximum likelihood estimation chapter of <a href="http://biostat.mc.vanderbilt.edu/rms">Regression Modeling Strategies</a> (<span class="citation">Harrell (<a href="#ref-rms2">2015</a>)</span>): <span class="math display">\[\text{Adequacy index} = \text{LR}_{A} / \text{LR}_{AB}\]</span> where the base model is denoted by A, the added predictors (e.g., biomarkers) are denoted by B, AB represents the combined model with A and B as predictors, and LR is defined above. Here adequacy refers to the adequacy of the model that ignores the new predictors.</p>
<p>Whether using the adequacy index or relative variation explained, one minus such an index is the fraction of new information provided by predictors in B. It is the proportion of explainable variation that is explained by B.</p>
<p>To emphasize the simplicity of relative explained variation, it is just the ratio of variances of predicted values. And other statistical indexes may be computed from the predicted values, such as the mean absolute difference from the mean predicted value, and the <span class="math inline">\(g\)</span> index described in <em>Regression Modeling Strategies</em>. The latter is the mean absolute difference between any two predicted values. But it is possible for the <span class="math inline">\(g\)</span> index for AB to be smaller than that for model A.</p>
</div>
</div>
<div id="case-study-quantifying-diagnostic-information" class="section level1">
<h1>Case Study: Quantifying Diagnostic Information</h1>
<p>Consider a series of patients from the Duke Cardiovascular Disease Databank. These patients were referred to Duke University Medical Center for chest pain and underwent cardiac catheterization during which a dye is injected and a coronary angiography is used to view blockages of coronary arteries. Significant coronary artery disease is here defined as a blockage of at least 75% by vessel diameter, in at least one major coronary artery. Here we consider total cholesterol as if it were a new diagnostic marker, and we wish to quantify the new diagnostic information provided by cholesterol. The base model is oversimplified for purposes of illustration. It contains only the powerful variables age and sex. In practice it should contain in addition to age and sex all relevant easily available baseline variables, such as pain characteristics, blood pressure, smoking history, etc. From previous analysis, a nonlinear interaction was demonstrated between age and sex and between age and cholesterol. The former is related to women “catching up” with men with respect to cardiovascular risk, after menopause. The latter interaction captures the fact that high cholesterol is not as dangerous for older patients and the possibility that very low cholesterol is actually harmful for them.</p>
<p>The dataset is available from the Vanderbilt Department of Biostatistics wiki, and includes 2258 patients with all variables measured. It may be automatically downloaded using the R <code>Hmisc getHdata</code> function. The dataset is also analyzed in the <a href="http://hbiostat.org/doc/bbr.pdf">BBR diagnosis chapter</a> and <a href="http://hbiostat.org/talks/memtab18.pdf">here</a>. The latter link contains more analyses that compare pre- and post-test probabilities.</p>
<div id="development-of-binary-logistic-model" class="section level2">
<h2>Development of Binary Logistic Model</h2>
<p>We first fit a binary logistic regression model with interactions, modeling age and cholesterol in a smooth nonlinear fashion using restricted cubic splines with default knot<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> locations. The nonlinear interaction between age and cholesterol is a restricted one such that terms that are nonlinear in both predictors are excluded. This is to save degrees of freedom. The code below also fits the base model containing only age and sex.</p>
<p>Estimated log odds of the risk of significant CAD is plotted against cholesterol for ages 40 and 70 years for males. One can readily see that the diagnostic value of cholesterol is greater for younger patients, and there is some evidence that very low total cholesterol is risky at age 70.</p>
<pre class="r"><code>require(rms)</code></pre>
<pre class="r"><code>options(prType=&#39;html&#39;)
getHdata(acath)
acath &lt;- subset(acath, !is.na(choleste))
acath$sex &lt;- factor(acath$sex, 0:1, c(&#39;male&#39;, &#39;female&#39;))
dd &lt;- datadist(acath);  options(datadist=&#39;dd&#39;)
f &lt;- lrm(sigdz ~ rcs(age,4) * sex, data=acath)
f</code></pre>
<div align="center">
<strong>Logistic Regression Model</strong>
</div>
<pre>
 lrm(formula = sigdz ~ rcs(age, 4) * sex, data = acath)
 </pre>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Model Likelihood<br>Ratio Test
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Discrimination<br>Indexes
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Rank Discrim.<br>Indexes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
Obs 2258
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
LR χ<sup>2</sup> 489.51
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>R</i><sup>2</sup> 0.270
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>C</i> 0.770
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
0 768
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
d.f. 7
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i> 1.216
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>D</i><sub>xy</sub> 0.539
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
1 1490
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
Pr(&gt;χ<sup>2</sup>) &lt;0.0001
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i><sub>r</sub> 3.372
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
γ 0.546
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
max |∂log <i>L</i>/∂β| 1×10<sup>-7</sup>
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i><sub>p</sub> 0.242
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
τ<sub>a</sub> 0.242
</td>
</tr>
<tr>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
Brier 0.177
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
</tr>
</tbody>
</table>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
β
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
S.E.
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Wald <i>Z</i>
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Pr(&gt;|<i>Z</i>|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
Intercept
</td>
<td style="min-width: 7em; text-align: right;">
 -3.9266
</td>
<td style="min-width: 7em; text-align: right;">
 0.8405
</td>
<td style="min-width: 7em; text-align: right;">
-4.67
</td>
<td style="min-width: 7em; text-align: right;">
&lt;0.0001
</td>
</tr>
<tr>
<td style="text-align: left;">
age
</td>
<td style="min-width: 7em; text-align: right;">
  0.1130
</td>
<td style="min-width: 7em; text-align: right;">
 0.0213
</td>
<td style="min-width: 7em; text-align: right;">
5.30
</td>
<td style="min-width: 7em; text-align: right;">
&lt;0.0001
</td>
</tr>
<tr>
<td style="text-align: left;">
age’
</td>
<td style="min-width: 7em; text-align: right;">
 -0.0761
</td>
<td style="min-width: 7em; text-align: right;">
 0.0658
</td>
<td style="min-width: 7em; text-align: right;">
-1.16
</td>
<td style="min-width: 7em; text-align: right;">
0.2477
</td>
</tr>
<tr>
<td style="text-align: left;">
age’’
</td>
<td style="min-width: 7em; text-align: right;">
  0.1890
</td>
<td style="min-width: 7em; text-align: right;">
 0.2856
</td>
<td style="min-width: 7em; text-align: right;">
0.66
</td>
<td style="min-width: 7em; text-align: right;">
0.5082
</td>
</tr>
<tr>
<td style="text-align: left;">
sex=female
</td>
<td style="min-width: 7em; text-align: right;">
  2.2574
</td>
<td style="min-width: 7em; text-align: right;">
 1.5121
</td>
<td style="min-width: 7em; text-align: right;">
1.49
</td>
<td style="min-width: 7em; text-align: right;">
0.1355
</td>
</tr>
<tr>
<td style="text-align: left;">
age × sex=female
</td>
<td style="min-width: 7em; text-align: right;">
 -0.0930
</td>
<td style="min-width: 7em; text-align: right;">
 0.0378
</td>
<td style="min-width: 7em; text-align: right;">
-2.46
</td>
<td style="min-width: 7em; text-align: right;">
0.0138
</td>
</tr>
<tr>
<td style="text-align: left;">
age’ × sex=female
</td>
<td style="min-width: 7em; text-align: right;">
  0.0629
</td>
<td style="min-width: 7em; text-align: right;">
 0.1073
</td>
<td style="min-width: 7em; text-align: right;">
0.59
</td>
<td style="min-width: 7em; text-align: right;">
0.5577
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
age’’ × sex=female
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
  0.0905
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
 0.4412
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
0.21
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
0.8375
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>pre &lt;- predict(f, type=&#39;fitted&#39;)    # pre-test probability
g &lt;- lrm(sigdz ~ rcs(age,4) * sex + rcs(choleste,4) + rcs(age,4) %ia%
         rcs(choleste,4), data=acath)
g</code></pre>
<div align="center">
<strong>Logistic Regression Model</strong>
</div>
<pre>
 lrm(formula = sigdz ~ rcs(age, 4) * sex + rcs(choleste, 4) + 
     rcs(age, 4) %ia% rcs(choleste, 4), data = acath)
 </pre>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Model Likelihood<br>Ratio Test
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Discrimination<br>Indexes
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Rank Discrim.<br>Indexes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
Obs 2258
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
LR χ<sup>2</sup> 596.99
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>R</i><sup>2</sup> 0.322
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>C</i> 0.795
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
0 768
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
d.f. 15
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i> 1.401
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>D</i><sub>xy</sub> 0.590
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
1 1490
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
Pr(&gt;χ<sup>2</sup>) &lt;0.0001
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i><sub>r</sub> 4.060
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
γ 0.590
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
max |∂log <i>L</i>/∂β| 4×10<sup>-5</sup>
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i><sub>p</sub> 0.266
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
τ<sub>a</sub> 0.265
</td>
</tr>
<tr>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
Brier 0.167
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
</tr>
</tbody>
</table>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: center;">
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
β
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
S.E.
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Wald <i>Z</i>
</th>
<th style="border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Pr(&gt;|<i>Z</i>|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
Intercept
</td>
<td style="min-width: 7em; text-align: right;">
 -7.3635
</td>
<td style="min-width: 7em; text-align: right;">
 4.9896
</td>
<td style="min-width: 7em; text-align: right;">
-1.48
</td>
<td style="min-width: 7em; text-align: right;">
0.1400
</td>
</tr>
<tr>
<td style="text-align: left;">
age
</td>
<td style="min-width: 7em; text-align: right;">
  0.1688
</td>
<td style="min-width: 7em; text-align: right;">
 0.1113
</td>
<td style="min-width: 7em; text-align: right;">
1.52
</td>
<td style="min-width: 7em; text-align: right;">
0.1292
</td>
</tr>
<tr>
<td style="text-align: left;">
age’
</td>
<td style="min-width: 7em; text-align: right;">
  0.0364
</td>
<td style="min-width: 7em; text-align: right;">
 0.2516
</td>
<td style="min-width: 7em; text-align: right;">
0.14
</td>
<td style="min-width: 7em; text-align: right;">
0.8850
</td>
</tr>
<tr>
<td style="text-align: left;">
age’’
</td>
<td style="min-width: 7em; text-align: right;">
  0.0410
</td>
<td style="min-width: 7em; text-align: right;">
 1.0461
</td>
<td style="min-width: 7em; text-align: right;">
0.04
</td>
<td style="min-width: 7em; text-align: right;">
0.9687
</td>
</tr>
<tr>
<td style="text-align: left;">
sex=female
</td>
<td style="min-width: 7em; text-align: right;">
  3.0665
</td>
<td style="min-width: 7em; text-align: right;">
 1.6093
</td>
<td style="min-width: 7em; text-align: right;">
1.91
</td>
<td style="min-width: 7em; text-align: right;">
0.0567
</td>
</tr>
<tr>
<td style="text-align: left;">
choleste
</td>
<td style="min-width: 7em; text-align: right;">
  0.0145
</td>
<td style="min-width: 7em; text-align: right;">
 0.0256
</td>
<td style="min-width: 7em; text-align: right;">
0.57
</td>
<td style="min-width: 7em; text-align: right;">
0.5709
</td>
</tr>
<tr>
<td style="text-align: left;">
choleste’
</td>
<td style="min-width: 7em; text-align: right;">
  0.0316
</td>
<td style="min-width: 7em; text-align: right;">
 0.0889
</td>
<td style="min-width: 7em; text-align: right;">
0.36
</td>
<td style="min-width: 7em; text-align: right;">
0.7226
</td>
</tr>
<tr>
<td style="text-align: left;">
choleste’’
</td>
<td style="min-width: 7em; text-align: right;">
 -0.1417
</td>
<td style="min-width: 7em; text-align: right;">
 0.2811
</td>
<td style="min-width: 7em; text-align: right;">
-0.50
</td>
<td style="min-width: 7em; text-align: right;">
0.6142
</td>
</tr>
<tr>
<td style="text-align: left;">
age × choleste
</td>
<td style="min-width: 7em; text-align: right;">
 -0.0003
</td>
<td style="min-width: 7em; text-align: right;">
 0.0006
</td>
<td style="min-width: 7em; text-align: right;">
-0.51
</td>
<td style="min-width: 7em; text-align: right;">
0.6072
</td>
</tr>
<tr>
<td style="text-align: left;">
age × choleste’
</td>
<td style="min-width: 7em; text-align: right;">
  0.0002
</td>
<td style="min-width: 7em; text-align: right;">
 0.0017
</td>
<td style="min-width: 7em; text-align: right;">
0.12
</td>
<td style="min-width: 7em; text-align: right;">
0.9016
</td>
</tr>
<tr>
<td style="text-align: left;">
age × choleste’’
</td>
<td style="min-width: 7em; text-align: right;">
  0.0005
</td>
<td style="min-width: 7em; text-align: right;">
 0.0055
</td>
<td style="min-width: 7em; text-align: right;">
0.09
</td>
<td style="min-width: 7em; text-align: right;">
0.9296
</td>
</tr>
<tr>
<td style="text-align: left;">
age’ × choleste
</td>
<td style="min-width: 7em; text-align: right;">
 -0.0004
</td>
<td style="min-width: 7em; text-align: right;">
 0.0011
</td>
<td style="min-width: 7em; text-align: right;">
-0.40
</td>
<td style="min-width: 7em; text-align: right;">
0.6866
</td>
</tr>
<tr>
<td style="text-align: left;">
age’’ × choleste
</td>
<td style="min-width: 7em; text-align: right;">
  0.0004
</td>
<td style="min-width: 7em; text-align: right;">
 0.0046
</td>
<td style="min-width: 7em; text-align: right;">
0.09
</td>
<td style="min-width: 7em; text-align: right;">
0.9301
</td>
</tr>
<tr>
<td style="text-align: left;">
age × sex=female
</td>
<td style="min-width: 7em; text-align: right;">
 -0.1134
</td>
<td style="min-width: 7em; text-align: right;">
 0.0402
</td>
<td style="min-width: 7em; text-align: right;">
-2.82
</td>
<td style="min-width: 7em; text-align: right;">
0.0048
</td>
</tr>
<tr>
<td style="text-align: left;">
age’ × sex=female
</td>
<td style="min-width: 7em; text-align: right;">
  0.0687
</td>
<td style="min-width: 7em; text-align: right;">
 0.1140
</td>
<td style="min-width: 7em; text-align: right;">
0.60
</td>
<td style="min-width: 7em; text-align: right;">
0.5468
</td>
</tr>
<tr>
<td style="border-bottom: 2px solid grey; text-align: left;">
age’’ × sex=female
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
  0.1509
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
 0.4678
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
0.32
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
0.7471
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>post &lt;- predict(g, type=&#39;fitted&#39;)   # post-test probability
ageg &lt;- c(40, 70)                   # test=cholesterol
psig &lt;- Predict(g, choleste, age=ageg, sex=&#39;male&#39;, fun=plogis)
ggplot(psig, adj.subtitle=FALSE, ylab=&#39;Prob(CAD)&#39;)</code></pre>
<p><img src="/post/addvalue_files/figure-html/fit-1.png" width="672" /></p>
</div>
<div id="visualizing-information-provided-by-cholesterol-by-analyzing-pre--and-post-test-probabilities" class="section level2">
<h2>Visualizing Information Provided by Cholesterol By Analyzing Pre- and Post-test Probabilities</h2>
<p>The most basic display of added value is back-to-back high-resolution histograms of pre- and post-test predicted risks. When the new markers add clinically important predictive information, the histogram widens.</p>
<pre class="r"><code>par(mgp=c(4,1,0), mar=c(6,5,2,2))
xlab &lt;- c(paste0(&#39;Pre-test\nvariance=&#39;, round(var(pre), 3)),
          paste0(&#39;Post-test\nvariance=&#39;,round(var(post), 3)))
histbackback(pre, post, brks=seq(0.01, 0.99, by=0.01), xlab=xlab, ylab=&#39;Prob(CAD)&#39;)</code></pre>
<p><img src="/post/addvalue_files/figure-html/hist-1.png" width="672" /></p>
<p>Another good way to visualize the diagnostic yield of cholesterol is to plot estimated post vs. pre-test probability of CAD. We use quantile regression to estimate the 0.1 and 0.9 quantiles of post-test risk as a function of pre-test risk. This allows one to readily see the typical changes in a pre-test probability once cholesterol is known.</p>
<pre class="r"><code>plot(pre, post, xlab=&#39;Pre-Test Probability (age + sex)&#39;,
     ylab=&#39;Post-Test Probability\n(age + sex + cholesterol)&#39;, pch=46)
abline(a=0, b=1, col=gray(.8))
lo &lt;- Rq(post ~ rcs(pre, 7), tau=0.1)  # 0.1 quantile
hi &lt;- Rq(post ~ rcs(pre, 7), tau=0.9)  # 0.9 quantile
at &lt;- seq(0, 1, length=200)
lines(at, Predict(lo, pre=at)$yhat, col=&#39;red&#39;, lwd=1.5)
lines(at, Predict(hi, pre=at)$yhat, col=&#39;red&#39;, lwd=1.5)
abline(v=.5, col=&#39;red&#39;)</code></pre>
<p><img src="/post/addvalue_files/figure-html/prepost-1.png" width="672" /></p>
<p>By plotting the pre-post risk difference vs. age we can easily see the dependence on age of the added value of cholesterol. We show the data for males.</p>
<pre class="r"><code>d &lt;- cbind(acath, pre=pre, post=post)
with(subset(d, sex == &#39;male&#39;),
 {
  lo &lt;- Rq(post - pre ~ rcs(age, 5), tau=0.1)
  hi &lt;- Rq(post - pre ~ rcs(age, 5), tau=0.9)
  at &lt;- seq(min(age), max(age), length=200)
  w &lt;- data.frame(age=at, lo=Predict(lo, age=at)$yhat,
                          hi=Predict(hi, age=at)$yhat)
  ggfreqScatter(age, post - pre,
                xlab=&#39;Age&#39;, ylab=&#39;Estimated Post - Pre-test Probability&#39;) +
     geom_line(aes(x=age, y=lo), data=w, inherit.aes=FALSE) +
     geom_line(aes(x=age, y=hi), data=w, inherit.aes=FALSE) +
     geom_hline(aes(yintercept=0), col=&#39;red&#39;)
  })</code></pre>
<p><img src="/post/addvalue_files/figure-html/vsage-1.png" width="672" /></p>
</div>
<div id="statistical-indexes-for-added-value-of-cholesterol" class="section level2">
<h2>Statistical Indexes for Added Value of Cholesterol</h2>
<p>The gold standard LR test for added value of cholesterol is obtained by comparing log likelihoods of the pre and post-test models. Cholesterol has a total of 8 parammeters; 5 for interacting with the spline function of age and 3 for its main effect<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Before getting the 8 d.f. LR test, let’s also get the LR test for interaction between cholesterol and age.</p>
<pre class="r"><code>h &lt;- lrm(sigdz ~ rcs(age,4)*sex + rcs(choleste,4), data=acath)
lrtest(h, g)   # test interaction</code></pre>
<pre><code>
Model 1: sigdz ~ rcs(age, 4) * sex + rcs(choleste, 4)
Model 2: sigdz ~ rcs(age, 4) * sex + rcs(choleste, 4) + rcs(age, 4) %ia% 
    rcs(choleste, 4)

 L.R. Chisq        d.f.           P 
11.19828202  5.00000000  0.04758732 </code></pre>
<pre class="r"><code>lrtest(f, g)   # test cholesterol as main or interacting effect</code></pre>
<pre><code>
Model 1: sigdz ~ rcs(age, 4) * sex
Model 2: sigdz ~ rcs(age, 4) * sex + rcs(choleste, 4) + rcs(age, 4) %ia% 
    rcs(choleste, 4)

L.R. Chisq       d.f.          P 
  107.4788     8.0000     0.0000 </code></pre>
<p>From the last test there is very strong evidence that cholesterol adds diagnostic value. The question is to what extent. So we turn to the various indexes discussed earlier—indexes that are sample-size independent, unlike the LR <span class="math inline">\(\chi^2\)</span> statistic that doubles when the sample size doubles, all else being equal.
As with the graphical summaries above, our indexes require no binning of data and fully allow for cholesterol to have varying importance as a function of age.</p>
<p>The detailed statistics that were listed for the pre- and post-test models above provide the LR <span class="math inline">\(\chi^2\)</span>, Nagelkerke pseudo <span class="math inline">\(R^2\)</span>, three <span class="math inline">\(g\)</span> indexes (log odds ratio scale, odds ratio scale, and risk scale), Brier score, <span class="math inline">\(c\)</span>-index, Somers’ <span class="math inline">\(D_{xy}\)</span>, Goodman-Kruskal <span class="math inline">\(\gamma\)</span>, and Kendall’s <span class="math inline">\(\tau_a\)</span>, the latter three being rank correlations between predicted disease risk and actual disease presence. <span class="math inline">\(D_{xy}\)</span> is connected to <span class="math inline">\(c\)</span> by <span class="math inline">\(D_{xy} = 2 (c - \frac{1}{2})\)</span>.</p>
<div id="new-old-measures" class="section level3">
<h3>New Old Measures</h3>
<p>Now consider measures of explained variation in disease status, and relative explained variation. Recall that pre- and post-test predicted risks are stored in the variables <code>pre</code> and <code>post</code>, respectively.</p>
<pre class="r"><code>r   &lt;- function(x) round(x, 2)
s   &lt;- function(x) round(x, 3)
lra &lt;- f$stats[&#39;Model L.R.&#39;]
lrb &lt;- g$stats[&#39;Model L.R.&#39;]
ra  &lt;- f$stats[&#39;R2&#39;]
rb  &lt;- g$stats[&#39;R2&#39;]
br2 &lt;- function(p) var(p) / (var(p) + sum(p * (1 - p)) / length(p))</code></pre>
<p>In the table below, “Fraction of new information” is the proportion of total predictive information in age, sex, and cholesterol that was added by cholesterol (main effect + age interaction effect). “Fraction explained risk” is the <span class="math inline">\(R^2\)</span> measure explicitly for binary Y, i.e., the ratio of the variance of predicted risk to the sum of the variance of predicted risk and the average risk times (1 - risk), computed by the <code>br2</code> function above.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Index</th>
<th>Value</th>
<th>Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a</td>
<td>Pre-test LR <span class="math inline">\(\chi^2\)</span></td>
<td>489.51</td>
<td></td>
</tr>
<tr class="even">
<td>b</td>
<td>Post-test LR <span class="math inline">\(\chi^2\)</span></td>
<td>596.99</td>
<td></td>
</tr>
<tr class="odd">
<td>c</td>
<td>Adequacy of base model</td>
<td>0.82</td>
<td>a/b</td>
</tr>
<tr class="even">
<td>d</td>
<td>Fraction of new information from cholesterol</td>
<td>0.18</td>
<td>1-c</td>
</tr>
<tr class="odd">
<td>e</td>
<td>Pre-test Nagelkerke pseudo <span class="math inline">\(R^2\)</span></td>
<td>0.27</td>
<td></td>
</tr>
<tr class="even">
<td>f</td>
<td>Post-test Nagelkerke pseudo <span class="math inline">\(R^2\)</span></td>
<td>0.32</td>
<td></td>
</tr>
<tr class="odd">
<td>g</td>
<td>Variance of pre-test risk</td>
<td>0.047</td>
<td></td>
</tr>
<tr class="even">
<td>h</td>
<td>Variance of post-test risk</td>
<td>0.057</td>
<td></td>
</tr>
<tr class="odd">
<td>i</td>
<td>Relative explained variation</td>
<td>0.83</td>
<td>g/h</td>
</tr>
<tr class="even">
<td>j</td>
<td>Fraction of new information</td>
<td>0.17</td>
<td>1-i</td>
</tr>
<tr class="odd">
<td>k</td>
<td>Pre-test fraction explained risk</td>
<td>0.21</td>
<td></td>
</tr>
<tr class="even">
<td>l</td>
<td>Post-test fraction explained risk</td>
<td>0.25</td>
<td></td>
</tr>
<tr class="odd">
<td>m</td>
<td>Relative explained variation</td>
<td>0.83</td>
<td>k/l</td>
</tr>
<tr class="even">
<td>n</td>
<td>Fraction of new information</td>
<td>0.17</td>
<td>1-m</td>
</tr>
</tbody>
</table>
<p>By the various indexes in the above table, the fraction of total diagnostic information that was due to the “new” test (cholesterol) ranges from 0.16 to 0.17. My favorite measure for assessing the fraction of diagnostic information that is new information from cholesterol is given by row j, i.e., one minus the ratio of the variance of pre-test probability of disease <span class="math inline">\(\hat{P}\)</span> to the variance of post-test <span class="math inline">\(\hat{P}\)</span>. This is related to one of the most useful displays one can make: high-resolution histograms of pre- and post-test probabilities, where the emphasis is on the width of the distributions. More discriminating models provide a greater variety of predictions, subject to assuming the model is well-calibrated. See above for histograms for pre- and post-test predicted risks.</p>
</div>
</div>
<div id="analysis-conclusions" class="section level2">
<h2>Analysis Conclusions</h2>
<p>The diagnostic yield of cholesterol is age- and sex-dependent. Measuring cholesterol seldom allows one to rule in or rule out coronary disease with certainty. It adds a fraction of 0.17 of new diagnostic information to age and sex.</p>
</div>
</div>
<div id="areas-of-application" class="section level1">
<h1>Areas of Application</h1>
<p>The methods described here have wide applicability to diagnostic and prognostic research. One area in particular is ripe for applying the methods: genetics. Genetic markers have been touted as being valuable for diagnosis and prognosis. It would be worthwhile to quantify the added value of genetic markers using one of the above indexes, along with the graphics displaying diagnostic or prognostic yield for individual subjects.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-cho12simI">
<p>Choodari-Oskooei, Babak, Patrick Royston, and Mahesh K. B. Parmar. 2012. “A Simulation Study of Predictive Ability Measures in a Survival Model I: Explained Variation Measures.” <em>Stat Med</em> 31 (23): 2627–43. <a href="https://doi.org/10.1002/sim.4242">https://doi.org/10.1002/sim.4242</a>.</p>
</div>
<div id="ref-cho12simII">
<p>Choodari-Oskooei, B., P. Royston, and Mahesh K. B. Parmar. 2012. “A Simulation Study of Predictive Ability Measures in a Survival Model II: Explained Randomness and Predictive Accuracy.” <em>Stat Med</em> 31 (23): 2644–59. <a href="https://doi.org/10.1002/sim.5460">https://doi.org/10.1002/sim.5460</a>.</p>
</div>
<div id="ref-har82">
<p>Harrell, F. E., R. M. Califf, D. B. Pryor, K. L. Lee, and R. A. Rosati. 1982. “Evaluating the Yield of Medical Tests.” <em>JAMA</em> 247: 2543–6.</p>
</div>
<div id="ref-rms2">
<p>Harrell, Frank E. 2015. <em>Regression Modeling Strategies, with Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis</em>. Second edition. New York: Springer. <a href="https://doi.org/10.1007/978-3-319-19425-7\%0020">https://doi.org/10.1007/978-3-319-19425-7\%0020</a>.</p>
</div>
<div id="ref-ken88mea">
<p>Kent, John T., and John O’Quigley. 1988. “Measures of Dependence for Censored Survival Data.” <em>Biometrika</em> 75: 525–34.</p>
</div>
<div id="ref-sch03pre">
<p>Schemper, Michael. 2003. “Predictive Accuracy and Explained Variation.” <em>Stat Med</em> 22: 2299–2308.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The Wilcoxon, Spearman, and other rank tests are very powerful for testing for existence of an association, but not for assessing <em>differences</em> in the strength of association.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p><span class="citation">Schemper (<a href="#ref-sch03pre">2003</a>)</span> is an excellent paper advocating for measures based on absolute rather than squared differences.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Knots are locations of curvature changes, i.e., locations in the covariate space where cubic polynomials are joined together.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>The LR test could have easily tested multiple new biomarkers simultaneously.<a href="#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>
